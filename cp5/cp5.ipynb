{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CP 5 Aprendizaje de Máquinas\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine y Cross Validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1: Preprocesamiento del Dataset\n",
    "\n",
    "Vamos a trabajar con un dataset que contiene información acerca de pacientes (*gender, marital status, smoking status, age, etc*) con el ojetivo de predecir si es probable que tenga un ataque al corazón (*stroke*).\n",
    "Además se incorpora de manera artificial la característica *doctor* que representa el doctor que recolectó los datos, la cual más adelante será usada para agrupar los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def get_prep_data():\n",
    "    df = pd.read_csv(\n",
    "        \"./resources/healthcare-dataset-stroke-data.csv\"\n",
    "    )\n",
    "    df[\"ever_married\"] = (\n",
    "        df[\"ever_married\"].replace(\"Yes\", True).replace(\"No\", False)\n",
    "    )\n",
    "    df[\"gender\"] = df[\"gender\"].astype(\"category\")\n",
    "    df[\"smoking_status\"] = df[\"smoking_status\"].astype(\"category\")\n",
    "    df[\"Residence_type\"] = df[\"Residence_type\"].astype(\"category\")\n",
    "    df[\"work_type\"] = df[\"work_type\"].astype(\"category\")\n",
    "    df[\"doctor\"] = np.random.randint(0, 8, size=len(df))\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "df = get_prep_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación exploremos la estructura del dataset en cuestión:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observan variables categóricas las cuales es necesario codificar "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para codificar las variables categóricas que están representadas en el dataset como string, podemos usar un encoder de `sklearn`, `LabelEncoder`, que codifica los strings como números. El objetivo de la función `encode_features`, es dado un dataset como `DataFrame`, y una lista de características para codificar, modificar el dataset pasado como parámetro con las carcaterísticas codificadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_features(df: pd.DataFrame, features: List[str]):\n",
    "    # Your code here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Llamemos a la función, pasando las características que vimos que eran categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observemos el dataset resultante:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobemos si para todas las muestras observadas en el dataset se tienen valores válidos. Para ello no deben existir valores `NaN`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En caso de existir valores `NaN` estos deben ser eliminados o reemplazados por algún otro valor que sea válido y represente la ausencia de información para esa muestra.\n",
    "\n",
    "- Para reemplazar los valores `NaN`, se puede hacer uso de la función `fillna`, que recibe como parámetro el valor por el cual se quieren sustituir los valores `NaN`, esta función retorna un nuevo dataset con los valores sustituidos, o modifica el dataset existente al añadir el parámetro `inplace=True`\n",
    "\n",
    "- Para eliminar las filas que tienen un valor `NaN` se puede usar la función `dropna`. En caso de usar esta función, se debe además usar la función `reset_index(drop=True)`, para arreglar los índices del `DataFrame`. Ambas funciones retornan un nuevo dataset, modifican el dataset original con el parámetro `inplace=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobemos la cantidad de muestras correspondientes a cada clase (1 para stroke, 0 para no stroke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede apreciar estamos en presencia de un dataset altamente desbalanceado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función `get_X_y` separa el dataset según las columnas elegidas como características y la columna *stroke* que representa el objetivo a predecir. Además se separa la columna *doctor* por la cual se quiere agrupar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_X_y(train):\n",
    "    FEATURES = [\n",
    "        \"gender\",\n",
    "        \"age\",\n",
    "        \"hypertension\",\n",
    "        \"heart_disease\",\n",
    "        \"ever_married\",\n",
    "        \"work_type\",\n",
    "        \"Residence_type\",\n",
    "        \"avg_glucose_level\",\n",
    "        \"bmi\",\n",
    "        \"smoking_status\",\n",
    "    ]\n",
    "\n",
    "    GROUPS = \"doctor\"\n",
    "\n",
    "    TARGET = \"stroke\"\n",
    "\n",
    "    X = train[FEATURES]\n",
    "    y = train[TARGET]\n",
    "    groups = train[GROUPS]\n",
    "    return X, y, groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2: Clasificación usando Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-10T21:23:21.823054Z",
     "iopub.status.busy": "2022-04-10T21:23:21.822593Z",
     "iopub.status.idle": "2022-04-10T21:23:21.835587Z",
     "shell.execute_reply": "2022-04-10T21:23:21.83389Z",
     "shell.execute_reply.started": "2022-04-10T21:23:21.823015Z"
    }
   },
   "source": [
    "Se divide el dataset en conjunto de entrenamiento y conjunto de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y, groups = get_X_y(df)\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proponemos usar la clase `SVC` como implementación para Support Vector Machine, la cual podemos encontrar en `sklearn`, para entrenar un clasificador en el conjunto de entrenamiento obtenido. Por defecto `SVC` usa `rbf` como función de kernel. Es necesario inicializar el parámetro `probability` como `True` para poder obtener las probabilidades de la predicción, que serán usadas para evaluar el clasificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métricas\n",
    "\n",
    "Dado que estamos en presencia de un dataset desbalanceado es recomendado usar otras métricas en lugar de accuracy.\n",
    "\n",
    "En este caso proponemos usar AUC (*Area Under the Curve*) la cual es una medida de la habilidad del clasificador para distinguir entre las clases y se usa como una representación de la curva ROC. Cuanto mayor sea el AUC, mejor será el rendimiento del modelo para distinguir entre las clases positivas y negativas\n",
    "\n",
    "Una curva ROC (*receiver operating characteristic curve*) es un gráfico que muestra el rendimiento de un modelo de clasificación en todos los umbrales de clasificación. Esta curva traza dos parámetros: *True Positive Rate* (TPR) y *False Positive Rate* (FPR)\n",
    "- TPR = TP / (TP + FN)\n",
    "- FPR = FP / (FP + TN)\n",
    "\n",
    "TPR frente a FPR son trazados en diferentes umbrales de clasificación. Reducir el umbral de clasificación clasifica más elementos como positivos, lo que aumenta tanto los falsos positivos como los verdaderos positivos. La siguiente figura muestra una curva ROC típica.\n",
    "\n",
    "![aucphoto](./resources/auc.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUC la podemos encntrar en `sklearn.metrics` como `roc_auc_score`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluemos el modelo usando las métricas accuracy y AUC. \n",
    "\n",
    "Hay que tener en cuenta que a diferencia de accuracy que evalúa segun las clases resultantes de la predicción, en el caso de AUC se van a usar las probabilidades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_score = None    # Your code here \n",
    "auc_score = None    # Your code here\n",
    "print(f\"Accuracy: {acc_score:0.4f}\")\n",
    "print(f\"AUC: {auc_score:0.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline\n",
    "\n",
    "Para analizar si los resultados obtenidos son buenos se necesita una base que sirva como punto de referencia significativo con el que comparar. Esto es lo que se denomina *baseline*.\n",
    "\n",
    "Es algo simple pero poderoso pues una vez que se tenga una línea base se puede agregar o cambiar los algoritmos que se están probando o sus parámetros, y saber si ha mejorado su enfoque o solución al problema.\n",
    "\n",
    "Hay formas comunes que puede usar para calcular un *baseline*. Este resultado de referencia es la predicción más simple posible. Para algunos problemas, puede ser un resultado aleatorio, y en otros puede ser la predicción más común.\n",
    "\n",
    "En este caso proponemos usar como *baseline* que siempre se obtenga un resultado negativo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "### Cross Validation\n",
    "\n",
    "La validación cruzada (*Cross Validation*) es un método estadístico que se utiliza para estimar el rendimiento de los modelos de aprendizaje automático. Se utiliza para proteger contra el *overfit* en un modelo, particularmente en un caso donde la cantidad de datos puede ser limitada. \n",
    "\n",
    "En pocas palabras, en el proceso de validación cruzada, el dataset original se divide aleatoriamente en varias particiones. El modelo de aprendizaje automático se entrena en todas las particiones, excepto una. Después del entrenamiento, el modelo se prueba haciendo predicciones sobre la partición restante.\n",
    "\n",
    "En muchos casos, se realizan múltiples rondas de validación cruzada usando diferentes particiones, y sus resultados se promedian.\n",
    "\n",
    "Existen varias formas de obtener las particiones a usar en la validación cruzada, como los que aparecen a continuación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import (\n",
    "    TimeSeriesSplit,\n",
    "    KFold,\n",
    "    StratifiedKFold,\n",
    "    GroupKFold,\n",
    "    StratifiedGroupKFold\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contamos con un conjunto de funciones auxiliares que nos ayudarán a visualizar los diferentes tipos de validación cruzada. Para ello se usará un dataset creado artificialmente que se obtiene mediante la función `get_fake_X_y`. Con la función `plot_cv`, podemos graficar las divisiones que hace los diferentes tipos de validación cruzada, así como la distribución de clases y grupos del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "plt.style.use('seaborn-white')\n",
    "\n",
    "cmap_data = plt.cm.Paired\n",
    "cmap_cv = plt.cm.coolwarm\n",
    "\n",
    "def visualize_groups(classes, groups, name):\n",
    "    # Visualize dataset groups\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(\n",
    "        range(len(groups)),\n",
    "        [0.5] * len(groups),\n",
    "        c=groups,\n",
    "        marker=\"_\",\n",
    "        lw=50,\n",
    "        cmap=cmap_data,\n",
    "    )\n",
    "    ax.scatter(\n",
    "        range(len(groups)),\n",
    "        [3.5] * len(groups),\n",
    "        c=classes,\n",
    "        marker=\"_\",\n",
    "        lw=50,\n",
    "        cmap=cmap_data,\n",
    "    )\n",
    "    ax.set(\n",
    "        ylim=[-1, 5],\n",
    "        yticks=[0.5, 3.5],\n",
    "        yticklabels=[\"Data\\ngroup\", \"Data\\nclass\"],\n",
    "        xlabel=\"Sample index\",\n",
    "    )\n",
    "\n",
    "\n",
    "def plot_cv_indices(cv, X, y, group, ax, n_splits, lw=25):\n",
    "    \"\"\"Create a sample plot for indices of a cross-validation object.\"\"\"\n",
    "\n",
    "    # Generate the training/testing visualizations for each CV split\n",
    "    for ii, (tr, tt) in enumerate(cv.split(X=X, y=y, groups=group)):\n",
    "        # Fill in indices with the training/test groups\n",
    "        indices = np.array([np.nan] * len(X))\n",
    "        indices[tt] = 1\n",
    "        indices[tr] = 0\n",
    "\n",
    "        # Visualize the results\n",
    "        ax.scatter(\n",
    "            range(len(indices)),\n",
    "            [ii + 0.5] * len(indices),\n",
    "            c=indices,\n",
    "            marker=\"_\",\n",
    "            lw=lw,\n",
    "            cmap=cmap_cv,\n",
    "            vmin=-0.2,\n",
    "            vmax=1.2,\n",
    "        )\n",
    "\n",
    "    # Plot the data classes and groups at the end\n",
    "    ax.scatter(\n",
    "        range(len(X)), [ii + 1.5] * len(X), c=y, marker=\"_\", lw=lw, cmap=cmap_data\n",
    "    )\n",
    "\n",
    "    ax.scatter(\n",
    "        range(len(X)), [ii + 2.5] * len(X), c=group, marker=\"_\", lw=lw, cmap=cmap_data\n",
    "    )\n",
    "\n",
    "    # Formatting\n",
    "    yticklabels = list(range(n_splits)) + [\"class\", \"group\"]\n",
    "    ax.set(\n",
    "        yticks=np.arange(n_splits + 2) + 0.5,\n",
    "        yticklabels=yticklabels,\n",
    "        xlabel=\"Sample index\",\n",
    "        ylabel=\"CV iteration\",\n",
    "        ylim=[n_splits + 2.2, -0.2],\n",
    "        xlim=[0, X.shape[0]],\n",
    "    )\n",
    "    ax.set_title(\"{}\".format(type(cv).__name__), fontsize=15)\n",
    "    return ax\n",
    "\n",
    "\n",
    "def plot_cv(cv, X, y, groups, n_splits=5):\n",
    "    this_cv = cv(n_splits=n_splits)\n",
    "    fig, ax = plt.subplots(figsize=(15, 5))\n",
    "    plot_cv_indices(this_cv, X, y, groups, ax, n_splits)\n",
    "\n",
    "    ax.legend(\n",
    "        [Patch(color=cmap_cv(0.8)), Patch(color=cmap_cv(0.02))],\n",
    "        [\"Testing set\", \"Training set\"],\n",
    "        loc=(1.02, 0.8),\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    fig.subplots_adjust(right=0.7)\n",
    "    plt.show()\n",
    "    \n",
    "def get_fake_X_y():\n",
    "    # Fake Generate the class/group data for an example\n",
    "    n_points = 100\n",
    "    X_ = np.random.randn(100, 10)\n",
    "\n",
    "    percentiles_classes = [0.1, 0.9]\n",
    "    y_ = np.hstack([[ii] * int(100 * perc) for ii, perc in enumerate(percentiles_classes)])\n",
    "\n",
    "    # Evenly spaced groups repeated once\n",
    "    groups_ = np.hstack([[ii] * 10 for ii in range(10)])\n",
    "    return X_, y_, groups_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KFold\n",
    "- Divide el conjunto de datos en k particiones consecutivas (por defecto no aleatoriza)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kf = KFold()\n",
    "X_, y_, groups_ = get_fake_X_y()\n",
    "plot_cv(KFold, X_, y_, groups_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratified KFold\n",
    "- KFold pero las particiones se realizan conservando la proporción de muestras para cada clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "skf = StratifiedKFold()\n",
    "X_, y_, groups_ = get_fake_X_y()\n",
    "plot_cv(StratifiedKFold, X_, y_, groups_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group KFold\n",
    "- Las particiones están equilibradas en el sentido de que el número de grupos distintos es aproximadamente el mismo en cada partición"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gkf = GroupKFold()\n",
    "X_, y_, groups_ = get_fake_X_y()\n",
    "plot_cv(GroupKFold, X_, y_, groups_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratified Group KFold\n",
    "\n",
    "La diferencia entre `GroupKFold` y `StratifiedGroupKFold` es que el primero intenta crear particiones equilibradas de modo que el número de grupos distintos sea aproximadamente el mismo en cada partición, mientras que `StratifiedGroupKFold` intenta crear pliegues que conserven el porcentaje de muestras para cada clase tanto como sea posible dada la restricción de grupos no superpuestos entre divisiones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gskf = StratifiedGroupKFold()\n",
    "X_, y_, groups_ = get_fake_X_y()\n",
    "np.random.shuffle(y_)\n",
    "plot_cv(StratifiedGroupKFold, X_, y_, groups_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Series Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Proporciona índices de entrenamiento/prueba para dividir muestras de datos de series temporales que se observan a intervalos de tiempo fijos, en conjuntos de entrenamiento/prueba. En cada división, los índices de prueba deben ser más altos que antes y, por lo tanto, la combinación aleatoria en el validador cruzado es inapropiada. Este objeto de validación cruzada es una variación de KFold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tss = TimeSeriesSplit()\n",
    "X_, y_, groups_ = get_fake_X_y()\n",
    "plot_cv(TimeSeriesSplit, X_, y_, groups_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3: Cross Validation aplicado a SVM "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora analicemos las características de nuestro dataset, para determinar cuál tipo de validación cruzada es el apropiado.\n",
    "\n",
    "Nuestro dataset es imbalanceado, y tiene grupos, así que `StratifiedGroupKFold` debe ser una buena elección. Grafiquemos cómo serían las divisiones. Primero, agrupemos los grupos para realizar una mejor visualización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = list(groups.groupby(groups).groups.values())\n",
    "flat_index = [item for sublist in idxs for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_, y_, groups_ = X.loc[flat_index], y.loc[flat_index], groups.loc[flat_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a realizar el entrenamiento usando el tipo de validación cruzada seleccionado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_with_cv(clf, cv=StratifiedGroupKFold):\n",
    "    sgk = cv(n_splits=5, shuffle=True, random_state=529)\n",
    "\n",
    "    X, y, groups = get_X_y(df)\n",
    "\n",
    "    fold = 0\n",
    "    aucs = []\n",
    "    for train_idx, val_idx in sgk.split(X, y, groups):\n",
    "        X_tr = X.loc[train_idx]\n",
    "        y_tr = y.loc[train_idx]\n",
    "\n",
    "        X_val = X.loc[val_idx]\n",
    "        y_val = y.loc[val_idx]\n",
    "\n",
    "        # Fit Model on Train\n",
    "        clf.fit(X_tr, y_tr)\n",
    "        pred = clf.predict_proba(X_val)[:,1]\n",
    "        auc_score = roc_auc_score(y_val, pred)\n",
    "        print(f\"======= Fold {fold} ========\")\n",
    "        print(\n",
    "            f\"El AUC en el conjunto de validación es {auc_score:0.4f}\"\n",
    "        )\n",
    "        fold += 1\n",
    "        aucs.append(auc_score)\n",
    "    oof_auc = np.mean(aucs)\n",
    "    print(f'El resultado AUC promediado es {oof_auc:0.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realicemos el entrenamiento con SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultado promediado es una estimación mucho mejor de cómo funcionará nuestro modelo en datos no vistos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 4: Cross Validation para el resto de los clasificadores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenemos en el dataset para predecir ataques al corazón cada uno de los clasificadores estudiados en el curso hasta el momento y evaluemos el rendimiento aplicando cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 5: Otros clasificadores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para concluir vamos a usar otros clasificadores que no son objetivo del curso y evaluarlos también usando cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "clf1 = GradientBoostingClassifier(n_estimators=100, learning_rate=1,max_depth=3, random_state=0)\n",
    "clf2 = HistGradientBoostingClassifier(min_samples_leaf=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_with_cv(clf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_with_cv(clf2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "# Cross Validation\n",
    "## The difference between a good model and an overfit one!\n",
    "This notebook goes along with a youtube created on the topic on Rob's youtube channel. [Check out the channel and video here.](https://www.youtube.com/channel/UCxladMszXan-jfgzyeIMyvw)\n",
    "\n",
    "![notsure](resources/shutterstock_493554238.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will learn:\n",
    "1. Example where not using cross validation causes us to believe our model is better than it is.\n",
    "2. Show the different cross validation techniuqes and when to apply them.\n",
    "3. Run our example from part 1 using the correct cross validation technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'StratifiedGroupKFold' from 'sklearn.model_selection' (C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-90-2c27510837fc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m from sklearn.model_selection import (\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mTimeSeriesSplit\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'StratifiedGroupKFold' from 'sklearn.model_selection' (C:\\Users\\Usuario\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from typing import List\n",
    "\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    TimeSeriesSplit,\n",
    "    KFold,\n",
    "    StratifiedKFold,\n",
    "    GroupKFold,\n",
    "    StratifiedGroupKFold\n",
    ")\n",
    "plt.style.use('seaborn-white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Dataset\n",
    "\n",
    "Stroke Prediction Data. Using information about patients, predict if they are likely to have a stroke.\n",
    "- Gender, marital status, smoking status, age, etc.\n",
    "- Also have a \"Doctor\" feature added to represent the \"group\" within the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_prep_data():\n",
    "    df = pd.read_csv(\n",
    "        \"./resources/healthcare-dataset-stroke-data.csv\"\n",
    "    )\n",
    "    df[\"ever_married\"] = (\n",
    "        df[\"ever_married\"].replace(\"Yes\", True).replace(\"No\", False)\n",
    "    )\n",
    "    df[\"gender\"] = df[\"gender\"].astype(\"category\")\n",
    "    df[\"smoking_status\"] = df[\"smoking_status\"].astype(\"category\")\n",
    "    df[\"Residence_type\"] = df[\"Residence_type\"].astype(\"category\")\n",
    "    df[\"work_type\"] = df[\"work_type\"].astype(\"category\")\n",
    "    df[\"doctor\"] = np.random.randint(0, 8, size=len(df))\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "df = get_prep_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_features(df: pd.DataFrame, features: List[str]):\n",
    "    le = LabelEncoder()\n",
    "    for feat in features:\n",
    "        df[feat] = le.fit_transform(df[feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_features(df, ['gender', 'work_type', 'Residence_type', 'smoking_status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bmi'].fillna(-1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df):\n",
    "    holdout_ids = df.sample(n=500, random_state=529).index\n",
    "    \n",
    "    train = (\n",
    "        df.loc[~df.index.isin(holdout_ids)]\n",
    "        .sample(frac=1, random_state=529)\n",
    "        .sort_values(\"doctor\")\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    holdout = (\n",
    "        df.loc[df.index.isin(holdout_ids)]\n",
    "        .sample(frac=1, random_state=529)\n",
    "        .sort_values(\"doctor\")\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    return train, holdout\n",
    "\n",
    "train, holdout = split_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_X_y(train):\n",
    "    FEATURES = [\n",
    "        \"gender\",\n",
    "        \"age\",\n",
    "        \"hypertension\",\n",
    "        \"heart_disease\",\n",
    "        \"ever_married\",\n",
    "        \"work_type\",\n",
    "        \"Residence_type\",\n",
    "        \"avg_glucose_level\",\n",
    "        \"bmi\",\n",
    "        \"smoking_status\",\n",
    "    ]\n",
    "\n",
    "    GROUPS = \"doctor\"\n",
    "\n",
    "    TARGET = \"stroke\"\n",
    "\n",
    "    X = train[FEATURES]\n",
    "    y = train[TARGET]\n",
    "    groups = train[GROUPS]\n",
    "    return X, y, groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, groups = get_X_y(train)\n",
    "clf = SVC()\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Predict on training set\n",
    "pred = clf.predict(X)\n",
    "# pred_prob = clf.predict_proba(X)[:, 1]\n",
    "\n",
    "acc_score = accuracy_score(y, pred)\n",
    "# auc_score = roc_auc_score(y, pred_prob)\n",
    "\n",
    "print(f'The score on the training set is accuracy: {acc_score:0.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model can predict with 99% accuracy!!!\n",
    "- NOPE!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check on a holdout set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_holdout, y_holdout, groups_holdout = get_X_y(holdout)\n",
    "\n",
    "pred = clf.predict(X_holdout)\n",
    "# pred_prob = clf.predict_proba(X_holdout)[:, 1]\n",
    "acc_score = accuracy_score(y_holdout, pred)\n",
    "# auc_score = roc_auc_score(y_holdout, pred_prob)\n",
    "print(\n",
    "    f\"Our accuracy on the holdout set is {acc_score:0.4f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline\n",
    "Predicting all zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "acc_score = accuracy_score(y_holdout, np.zeros_like(y_holdout))\n",
    "auc_score = roc_auc_score(y_holdout, np.zeros_like(y_holdout))\n",
    "print(\n",
    "    f\"Our baseline on the holdout set is {acc_score:0.4f} and AUC is {auc_score:0.4f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-10T21:23:21.823054Z",
     "iopub.status.busy": "2022-04-10T21:23:21.822593Z",
     "iopub.status.idle": "2022-04-10T21:23:21.835587Z",
     "shell.execute_reply": "2022-04-10T21:23:21.83389Z",
     "shell.execute_reply.started": "2022-04-10T21:23:21.823015Z"
    }
   },
   "source": [
    "# Train/Test Split\n",
    "\n",
    "\n",
    "![traintest](https://www.researchgate.net/profile/Brian-Mwandau/publication/325870973/figure/fig6/AS:639531594285060@1529487622235/Train-Test-Data-Split.png)\n",
    "\n",
    "Split the training data into a training and validation set. Train the model on the training set, and validate it on the validation set.\n",
    "- The most basic way of splitting data.\n",
    "- shuffle - Good idea to use to make sure the order isn't impacting your split.\n",
    "- stratified (even distribution of positive samples in each set). Consider using if you have a small or unbalanced dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X, y, groups = get_X_y(train)\n",
    "\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X, y, test_size=0.1)\n",
    "clf = SVC()\n",
    "clf.fit(X_tr, y_tr)\n",
    "pred = clf.predict(X_val)\n",
    "acc_score = accuracy_score(y_val, pred)\n",
    "print(\n",
    "    f\"Our accuracy on the validation set is {acc_score:0.4f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation!\n",
    "\n",
    "Visualizations adapted from [here](https://scikit-learn.org/stable/auto_examples/model_selection/plot_cv_indices.html#sphx-glr-auto-examples-model-selection-plot-cv-indices-py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matplotlib.patches import Patch\n",
    "cmap_data = plt.cm.Paired\n",
    "cmap_cv = plt.cm.coolwarm\n",
    "\n",
    "def visualize_groups(classes, groups, name):\n",
    "    # Visualize dataset groups\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(\n",
    "        range(len(groups)),\n",
    "        [0.5] * len(groups),\n",
    "        c=groups,\n",
    "        marker=\"_\",\n",
    "        lw=50,\n",
    "        cmap=cmap_data,\n",
    "    )\n",
    "    ax.scatter(\n",
    "        range(len(groups)),\n",
    "        [3.5] * len(groups),\n",
    "        c=classes,\n",
    "        marker=\"_\",\n",
    "        lw=50,\n",
    "        cmap=cmap_data,\n",
    "    )\n",
    "    ax.set(\n",
    "        ylim=[-1, 5],\n",
    "        yticks=[0.5, 3.5],\n",
    "        yticklabels=[\"Data\\ngroup\", \"Data\\nclass\"],\n",
    "        xlabel=\"Sample index\",\n",
    "    )\n",
    "\n",
    "\n",
    "def plot_cv_indices(cv, X, y, group, ax, n_splits, lw=25):\n",
    "    \"\"\"Create a sample plot for indices of a cross-validation object.\"\"\"\n",
    "\n",
    "    # Generate the training/testing visualizations for each CV split\n",
    "    for ii, (tr, tt) in enumerate(cv.split(X=X, y=y, groups=group)):\n",
    "        # Fill in indices with the training/test groups\n",
    "        indices = np.array([np.nan] * len(X))\n",
    "        indices[tt] = 1\n",
    "        indices[tr] = 0\n",
    "\n",
    "        # Visualize the results\n",
    "        ax.scatter(\n",
    "            range(len(indices)),\n",
    "            [ii + 0.5] * len(indices),\n",
    "            c=indices,\n",
    "            marker=\"_\",\n",
    "            lw=lw,\n",
    "            cmap=cmap_cv,\n",
    "            vmin=-0.2,\n",
    "            vmax=1.2,\n",
    "        )\n",
    "\n",
    "    # Plot the data classes and groups at the end\n",
    "    ax.scatter(\n",
    "        range(len(X)), [ii + 1.5] * len(X), c=y, marker=\"_\", lw=lw, cmap=cmap_data\n",
    "    )\n",
    "\n",
    "    ax.scatter(\n",
    "        range(len(X)), [ii + 2.5] * len(X), c=group, marker=\"_\", lw=lw, cmap=cmap_data\n",
    "    )\n",
    "\n",
    "    # Formatting\n",
    "    yticklabels = list(range(n_splits)) + [\"class\", \"group\"]\n",
    "    ax.set(\n",
    "        yticks=np.arange(n_splits + 2) + 0.5,\n",
    "        yticklabels=yticklabels,\n",
    "        xlabel=\"Sample index\",\n",
    "        ylabel=\"CV iteration\",\n",
    "        ylim=[n_splits + 2.2, -0.2],\n",
    "        xlim=[0, 100],\n",
    "    )\n",
    "    ax.set_title(\"{}\".format(type(cv).__name__), fontsize=15)\n",
    "    return ax\n",
    "\n",
    "\n",
    "def plot_cv(cv, X, y, groups, n_splits=5):\n",
    "    this_cv = cv(n_splits=n_splits)\n",
    "    fig, ax = plt.subplots(figsize=(15, 5))\n",
    "    plot_cv_indices(this_cv, X, y, groups, ax, n_splits)\n",
    "\n",
    "    ax.legend(\n",
    "        [Patch(color=cmap_cv(0.8)), Patch(color=cmap_cv(0.02))],\n",
    "        [\"Testing set\", \"Training set\"],\n",
    "        loc=(1.02, 0.8),\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    fig.subplots_adjust(right=0.7)\n",
    "    plt.show()\n",
    "    \n",
    "def get_fake_X_y():\n",
    "    # Fake Generate the class/group data for an example\n",
    "    n_points = 100\n",
    "    X_ = np.random.randn(100, 10)\n",
    "\n",
    "    percentiles_classes = [0.1, 0.9]\n",
    "    y_ = np.hstack([[ii] * int(100 * perc) for ii, perc in enumerate(percentiles_classes)])\n",
    "\n",
    "    # Evenly spaced groups repeated once\n",
    "    groups_ = np.hstack([[ii] * 10 for ii in range(10)])\n",
    "    return X_, y_, groups_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KFold\n",
    "- Split dataset into k consecutive folds (without shuffling by default)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kf = KFold()\n",
    "X_, y_, groups_ = get_fake_X_y()\n",
    "plot_cv(KFold, X_, y_, groups_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stratified KFold\n",
    "- KFold but the folds are made by preserving the percentage of samples for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "skf = StratifiedKFold()\n",
    "X_, y_, groups_ = get_fake_X_y()\n",
    "plot_cv(StratifiedKFold, X_, y_, groups_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group KFold\n",
    "\n",
    "The folds are approximately balanced in the sense that the number of distinct groups is approximately the same in each fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gkf = GroupKFold()\n",
    "X_, y_, groups_ = get_fake_X_y()\n",
    "plot_cv(GroupKFold, X_, y_, groups_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cv(GroupKFold, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stratified Group KFold\n",
    "\n",
    "The difference between GroupKFold and StratifiedGroupKFold is that the former attempts to create balanced folds such that the number of distinct groups is approximately the same in each fold, whereas StratifiedGroupKFold attempts to create folds which preserve the percentage of samples for each class as much as possible given the constraint of non-overlapping groups between splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# gskf = StratifiedGroupKFold()\n",
    "# X_, y_, groups_ = get_fake_X_y()\n",
    "# np.random.shuffle(y_)\n",
    "# plot_cv(StratifiedGroupKFold, X_, y_, groups_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tss = TimeSeriesSplit()\n",
    "X_, y_, groups_ = get_fake_X_y()\n",
    "np.random.shuffle(y_)\n",
    "plot_cv(TimeSeriesSplit, X_, y_, groups_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our Example Using Proper Cross Validation\n",
    "1. Small/imblanced -> Stratified\n",
    "2. Group\n",
    "3. Shuffle in on\n",
    "\n",
    "`StratifiedGroupKFold` is a good choice for this situation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sgk = StratifiedKFold(n_splits=5, shuffle=True, random_state=529)\n",
    "\n",
    "X, y, groups = get_X_y(train)\n",
    "\n",
    "fold = 0\n",
    "aucs = []\n",
    "for train_idx, val_idx in sgk.split(X, y, groups):\n",
    "    X_tr = X.loc[train_idx]\n",
    "    y_tr = y.loc[train_idx]\n",
    "    \n",
    "    X_val = X.loc[val_idx]\n",
    "    y_val = y.loc[val_idx]\n",
    "\n",
    "    # Fit Model on Train\n",
    "    clf = SVC()\n",
    "    clf.fit(X_tr, y_tr)\n",
    "    pred = clf.predict(X_val)\n",
    "    acc_score = accuracy_score(y_val, pred)\n",
    "    print(f\"======= Fold {fold} ========\")\n",
    "    print(\n",
    "        f\"Our accuracy on the validation set is {acc_score:0.4f}\"\n",
    "    )\n",
    "    fold += 1\n",
    "    aucs.append(acc_score)\n",
    "oof_auc = np.mean(aucs)\n",
    "print(f'Our out of fold AUC score is {oof_auc:0.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our averaged out of fold score is a much better estimation of how our model will perform on unseen data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

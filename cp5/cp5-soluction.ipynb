{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CP 5 Aprendizaje de Máquinas\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine y Cross Validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1: Preprocesamiento del Dataset\n",
    "\n",
    "Vamos a trabajar con un dataset que contiene información acerca de pacientes (*gender, marital status, smoking status, age, etc*) con el ojetivo de predecir si es probable que tenga un ataque al corazón (*stroke*).\n",
    "Además se incorpora de manera artificial la característica *doctor* que representa el doctor que recolectó los datos, la cual más adelante será usada para agrupar los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def get_prep_data():\n",
    "    df = pd.read_csv(\n",
    "        \"./resources/healthcare-dataset-stroke-data.csv\"\n",
    "    )\n",
    "    df[\"ever_married\"] = (\n",
    "        df[\"ever_married\"].replace(\"Yes\", True).replace(\"No\", False)\n",
    "    )\n",
    "    df[\"gender\"] = df[\"gender\"].astype(\"category\")\n",
    "    df[\"smoking_status\"] = df[\"smoking_status\"].astype(\"category\")\n",
    "    df[\"Residence_type\"] = df[\"Residence_type\"].astype(\"category\")\n",
    "    df[\"work_type\"] = df[\"work_type\"].astype(\"category\")\n",
    "    df[\"doctor\"] = np.random.randint(0, 8, size=len(df))\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "df = get_prep_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación exploremos la estructura del dataset en cuestión:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observan variables categóricas las cuales es necesario codificar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_features(df: pd.DataFrame, features: List[str]):\n",
    "    le = LabelEncoder()\n",
    "    for feat in features:\n",
    "        df[feat] = le.fit_transform(df[feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_features(df, ['gender', 'work_type', 'Residence_type', 'smoking_status'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observemos el dataset resultante:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobemos si para todas las muestras observadas en el dataset se tienen valores válidos. Para ello no deben existir valores `NaN`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En caso de existir valores `NaN` estos deben ser eliminados o reemplazados por algún otro valor que sea válido y represente la ausencia de información para esa muestra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bmi'].fillna(-1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobemos la cantidad de muestras correspondientes a cada clase (1 para stroke, 0 para no stroke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['stroke'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede apreciar estamos en presencia de un dataset altamente desbalanceado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función `get_X_y` separa el dataset según las columnas elegidas como características y la columna *stroke* que representa el objetivo a predecir. Además se separa la columna *doctor* por la cual se quiere agrupar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_X_y(train):\n",
    "    FEATURES = [\n",
    "        \"gender\",\n",
    "        \"age\",\n",
    "        \"hypertension\",\n",
    "        \"heart_disease\",\n",
    "        \"ever_married\",\n",
    "        \"work_type\",\n",
    "        \"Residence_type\",\n",
    "        \"avg_glucose_level\",\n",
    "        \"bmi\",\n",
    "        \"smoking_status\",\n",
    "    ]\n",
    "\n",
    "    GROUPS = \"doctor\"\n",
    "\n",
    "    TARGET = \"stroke\"\n",
    "\n",
    "    X = train[FEATURES]\n",
    "    y = train[TARGET]\n",
    "    groups = train[GROUPS]\n",
    "    return X, y, groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2: Clasificación usando Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-10T21:23:21.823054Z",
     "iopub.status.busy": "2022-04-10T21:23:21.822593Z",
     "iopub.status.idle": "2022-04-10T21:23:21.835587Z",
     "shell.execute_reply": "2022-04-10T21:23:21.83389Z",
     "shell.execute_reply.started": "2022-04-10T21:23:21.823015Z"
    }
   },
   "source": [
    "Se divide el dataset en conjunto de entrenamiento y conjunto de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y, groups = get_X_y(df)\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proponemos usar la clase `SVC` como implementación para Support Vector Machine, la cual podemos encontrar en `sklearn`, para entrenar un clasificador en el conjunto de entrenamiento obtenido. Por defecto `SVC` usa `rbf` como función de kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC()\n",
    "clf.fit(X_tr, y_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métricas\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "baseline = np.random.randint(0,2,y_val.shape)\n",
    "\n",
    "acc_score = accuracy_score(y_val, baseline)\n",
    "auc_score = roc_auc_score(y_val, baseline)\n",
    "print(\n",
    "    f\"Our baseline on the holdout set is {acc_score:0.4f} and AUC is {auc_score:0.4f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(X_val)\n",
    "\n",
    "acc_score_1 = accuracy_score(y_val, pred)\n",
    "auc_score_1 = roc_auc_score(y_val, pred)\n",
    "print(\n",
    "    f\"Accuracy on the validation set is {acc_score_1:0.4f} and AUC is {auc_score_1:0.4f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will learn:\n",
    "1. Example where not using cross validation causes us to believe our model is better than it is.\n",
    "2. Show the different cross validation techniuqes and when to apply them.\n",
    "3. Run our example from part 1 using the correct cross validation technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "plt.style.use('seaborn-white')\n",
    "\n",
    "cmap_data = plt.cm.Paired\n",
    "cmap_cv = plt.cm.coolwarm\n",
    "\n",
    "def visualize_groups(classes, groups, name):\n",
    "    # Visualize dataset groups\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(\n",
    "        range(len(groups)),\n",
    "        [0.5] * len(groups),\n",
    "        c=groups,\n",
    "        marker=\"_\",\n",
    "        lw=50,\n",
    "        cmap=cmap_data,\n",
    "    )\n",
    "    ax.scatter(\n",
    "        range(len(groups)),\n",
    "        [3.5] * len(groups),\n",
    "        c=classes,\n",
    "        marker=\"_\",\n",
    "        lw=50,\n",
    "        cmap=cmap_data,\n",
    "    )\n",
    "    ax.set(\n",
    "        ylim=[-1, 5],\n",
    "        yticks=[0.5, 3.5],\n",
    "        yticklabels=[\"Data\\ngroup\", \"Data\\nclass\"],\n",
    "        xlabel=\"Sample index\",\n",
    "    )\n",
    "\n",
    "\n",
    "def plot_cv_indices(cv, X, y, group, ax, n_splits, lw=25):\n",
    "    \"\"\"Create a sample plot for indices of a cross-validation object.\"\"\"\n",
    "\n",
    "    # Generate the training/testing visualizations for each CV split\n",
    "    for ii, (tr, tt) in enumerate(cv.split(X=X, y=y, groups=group)):\n",
    "        # Fill in indices with the training/test groups\n",
    "        indices = np.array([np.nan] * len(X))\n",
    "        indices[tt] = 1\n",
    "        indices[tr] = 0\n",
    "\n",
    "        # Visualize the results\n",
    "        ax.scatter(\n",
    "            range(len(indices)),\n",
    "            [ii + 0.5] * len(indices),\n",
    "            c=indices,\n",
    "            marker=\"_\",\n",
    "            lw=lw,\n",
    "            cmap=cmap_cv,\n",
    "            vmin=-0.2,\n",
    "            vmax=1.2,\n",
    "        )\n",
    "\n",
    "    # Plot the data classes and groups at the end\n",
    "    ax.scatter(\n",
    "        range(len(X)), [ii + 1.5] * len(X), c=y, marker=\"_\", lw=lw, cmap=cmap_data\n",
    "    )\n",
    "\n",
    "    ax.scatter(\n",
    "        range(len(X)), [ii + 2.5] * len(X), c=group, marker=\"_\", lw=lw, cmap=cmap_data\n",
    "    )\n",
    "\n",
    "    # Formatting\n",
    "    yticklabels = list(range(n_splits)) + [\"class\", \"group\"]\n",
    "    ax.set(\n",
    "        yticks=np.arange(n_splits + 2) + 0.5,\n",
    "        yticklabels=yticklabels,\n",
    "        xlabel=\"Sample index\",\n",
    "        ylabel=\"CV iteration\",\n",
    "        ylim=[n_splits + 2.2, -0.2],\n",
    "        xlim=[0, X.shape[0]],\n",
    "    )\n",
    "    ax.set_title(\"{}\".format(type(cv).__name__), fontsize=15)\n",
    "    return ax\n",
    "\n",
    "\n",
    "def plot_cv(cv, X, y, groups, n_splits=5):\n",
    "    this_cv = cv(n_splits=n_splits)\n",
    "    fig, ax = plt.subplots(figsize=(15, 5))\n",
    "    plot_cv_indices(this_cv, X, y, groups, ax, n_splits)\n",
    "\n",
    "    ax.legend(\n",
    "        [Patch(color=cmap_cv(0.8)), Patch(color=cmap_cv(0.02))],\n",
    "        [\"Testing set\", \"Training set\"],\n",
    "        loc=(1.02, 0.8),\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    fig.subplots_adjust(right=0.7)\n",
    "    plt.show()\n",
    "    \n",
    "def get_fake_X_y():\n",
    "    # Fake Generate the class/group data for an example\n",
    "    n_points = 100\n",
    "    X_ = np.random.randn(100, 10)\n",
    "\n",
    "    percentiles_classes = [0.1, 0.9]\n",
    "    y_ = np.hstack([[ii] * int(100 * perc) for ii, perc in enumerate(percentiles_classes)])\n",
    "\n",
    "    # Evenly spaced groups repeated once\n",
    "    groups_ = np.hstack([[ii] * 10 for ii in range(10)])\n",
    "    return X_, y_, groups_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import (\n",
    "    TimeSeriesSplit,\n",
    "    KFold,\n",
    "    StratifiedKFold,\n",
    "    GroupKFold,\n",
    "    StratifiedGroupKFold\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KFold\n",
    "- Split dataset into k consecutive folds (without shuffling by default)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "kf = KFold()\n",
    "X_, y_, groups_ = get_fake_X_y()\n",
    "plot_cv(KFold, X_, y_, groups_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stratified KFold\n",
    "- KFold but the folds are made by preserving the percentage of samples for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "skf = StratifiedKFold()\n",
    "X_, y_, groups_ = get_fake_X_y()\n",
    "plot_cv(StratifiedKFold, X_, y_, groups_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group KFold\n",
    "\n",
    "The folds are approximately balanced in the sense that the number of distinct groups is approximately the same in each fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gkf = GroupKFold()\n",
    "X_, y_, groups_ = get_fake_X_y()\n",
    "plot_cv(GroupKFold, X_, y_, groups_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_cv(GroupKFold, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stratified Group KFold\n",
    "\n",
    "The difference between GroupKFold and StratifiedGroupKFold is that the former attempts to create balanced folds such that the number of distinct groups is approximately the same in each fold, whereas StratifiedGroupKFold attempts to create folds which preserve the percentage of samples for each class as much as possible given the constraint of non-overlapping groups between splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gskf = StratifiedGroupKFold()\n",
    "X_, y_, groups_ = get_fake_X_y()\n",
    "np.random.shuffle(y_)\n",
    "plot_cv(StratifiedGroupKFold, X_, y_, groups_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tss = TimeSeriesSplit()\n",
    "X_, y_, groups_ = get_fake_X_y()\n",
    "np.random.shuffle(y_)\n",
    "plot_cv(TimeSeriesSplit, X_, y_, groups_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping the groups together\n",
    "indeces = list(groups.groupby(groups).groups.values())\n",
    "flat_index = [item for sublist in indeces for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_, y_, groups_ = X.loc[flat_index], y.loc[flat_index], groups.loc[flat_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cv(StratifiedGroupKFold, X_, y_, groups_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3: Cross Validation aplicado a SVM \n",
    "1. Small/imblanced -> Stratified\n",
    "2. Group\n",
    "3. Shuffle in on\n",
    "\n",
    "`StratifiedGroupKFold` is a good choice for this situation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_with_cv(clf):\n",
    "    sgk = StratifiedKFold(n_splits=5, shuffle=True, random_state=529)\n",
    "\n",
    "    X, y, groups = get_X_y(df)\n",
    "\n",
    "    fold = 0\n",
    "    aucs = []\n",
    "    for train_idx, val_idx in sgk.split(X, y, groups):\n",
    "        X_tr = X.loc[train_idx]\n",
    "        y_tr = y.loc[train_idx]\n",
    "\n",
    "        X_val = X.loc[val_idx]\n",
    "        y_val = y.loc[val_idx]\n",
    "\n",
    "        # Fit Model on Train\n",
    "        clf.fit(X_tr, y_tr)\n",
    "        pred = clf.predict(X_val)\n",
    "        auc_score = roc_auc_score(y_val, pred)\n",
    "        print(f\"======= Fold {fold} ========\")\n",
    "        print(\n",
    "            f\"Our AUC on the validation set is {auc_score:0.4f}\"\n",
    "        )\n",
    "        fold += 1\n",
    "        aucs.append(auc_score)\n",
    "    oof_auc = np.mean(aucs)\n",
    "    print(f'Our out of fold AUC score is {oof_auc:0.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_with_cv(SVC())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our averaged out of fold score is a much better estimation of how our model will perform on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 4: Cross Validation para el resto de los clasificadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "train_with_cv(GaussianNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "train_with_cv(KNeighborsClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "train_with_cv(DecisionTreeClassifier(criterion=\"entropy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "train_with_cv(RandomForestClassifier(criterion=\"entropy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "train_with_cv(LogisticRegression(solver='liblinear'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

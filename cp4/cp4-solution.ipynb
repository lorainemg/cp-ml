{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CP 4 Aprendizaje de Máquinas\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión Logística\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta clase práctica, seguiremos usando el dataset de _Rotten Tomatoes_ para clasificar críticas positivas y negativas. Como en las clases anteriores, extraemos el contenido de los archivos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "path_p = Path(\"txt_sentoken/pos\")\n",
    "path_n = Path(\"txt_sentoken/neg\")\n",
    "\n",
    "# directorio donde están las críticas positivas\n",
    "ds_p = list(path_p.iterdir())\n",
    "# directorio donde están las críticas negativas\n",
    "ds_n = list(path_n.iterdir())\n",
    "\n",
    "\n",
    "def convert_file_to_text(file_path: Path) -> str:\n",
    "    with open(file_path) as f:\n",
    "        return ''.join(f.readlines())\n",
    "\n",
    "\n",
    "# Lista de críticas positivas\n",
    "texts_p = [convert_file_to_text(file) for file in ds_p]\n",
    "# Lista de críticas negativas\n",
    "texts_n = [convert_file_to_text(file) for file in ds_n]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 1: Regresión Logística aplicado al dataset de _Rotten Tomatoes_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apliquemos el algoritmo visto en conferencia, Regresión Logística, para la clasificación de las críticas de _Rotten Tomatoes_. Comenzamos usando, como siempre, `CountVectorizer` para obtener una representación de bolsas de palabras en el dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(texts_p + texts_n)\n",
    "X = X.toarray()\n",
    "\n",
    "y = [1]*1000 + [0]*1000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobamos el tamaño del vector de características:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividimos la matriz de características y el vector de clase en conjuntos de entrenamiento y de prueba, usando el 70% del dataset para entrenamiento. Esta vez, se usa el parámetro `random_state` para obtener la misma división en llamadas sucesivas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, train_size=0.70, random_state=23)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usemos ahora el clasificador `LogisticRegression` para realizar el entrenamiento y predicción del dataset en cuestión. El parámetro `solver` de `LogisticRegression` especifica el algoritmo de optimización a usar durante el entrenamiento. En caso que sea requerido, usar uno más sencillo como `liblinear` en vez del que tiene por defecto `sklearn` puede simplificar el proceso de entrenamiento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = LogisticRegression(solver='liblinear')\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_model.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 2: Visualizando la Matriz de Confusión\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el siguiente ejercicio, visualicemos la matriz de confusión, que especifica de los ejemplos negativos y positivos, cuáles fueron correctamente clasificados como negativos y positivos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = plot_confusion_matrix(lr_model, X_test, y_test,\n",
    "                             display_labels=[\n",
    "                                 'Negative Class', 'Positive Class'],\n",
    "                             cmap=plt.cm.Blues,\n",
    "                             normalize='true')\n",
    "disp.ax_.set_title('Logistic Regression Confusion matrix, with normalization')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 3: Probando la clasificación de un texto en específico\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, mostramos cómo se podría realizar la clasificación de un ejemplo específico, para ellos, comprobemos el orden en que las clases son mostradas mediante la propiedad `classes_` de la instancia de `LogisticRegression`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model.classes_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para probar el clasificador en un ejemplo específico, se debe primero vectorizar la oración de entrada, llamando el método `transform` _vectorizer_, que recibe una lista de _strings_. Luego, el método `predict` recibe la matriz de características y retorna un `array` con las clases clasificadas. El método `predict_proba` da más información, mostrando las probabilidades de pertenencia de cada clase, de acuerdo al orden mostrado de las clases en el método anterior.\n",
    "\n",
    "Probemos un ejemplo interesante, '_The movie was not fun to watch_', que a pesar de presentar una palabra que podría considerarse positiva ('_fun_', esta se encuentra negada y es en realidad una crítica negativa.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_review = cv.transform([\"The movie was not fun to watch\"])\n",
    "lr_model.predict_proba(test_review)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 4: Vizualizando las Características más Importantes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, visualicemos las características más importantes, es decir, las palabras más importantes para clasificar una crítica como negativa o positiva.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ello, tenemos que usar la propiedad de `Logistic Regression` de sklearn, `coef_`, que cuando el problema es binario nos brinda un `ndarray` de dimensión `(1,n_features)` que contiene los coeficiente de las características que resultan del entrenamiento.\n",
    "\n",
    "Luego, se crea `sorted_idx`, que contiene el índice de las características (palabras) que ordenarían el array según su importancia (de menor a mayor).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = lr_model.coef_[0]\n",
    "sorted_idx = np.argsort(feature_importance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método auxiliar, `get_word`, dado el índice resultante de `sorted_idx`, retorna la palabra que le corresponde a dicho índice.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word(cv: CountVectorizer, w_idx: int) -> str:\n",
    "    \"Given the index of a word, finds in the vocabulary of the CountVectorizer the word\"\n",
    "    return list(cv.vocabulary_.keys())[list(cv.vocabulary_.values()).index(w_idx)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtengamos entonces el orden de las 10 palabras más importantes para clasificar una crítica como positiva. Notar que las características positivas son aquellas que tienen un mayor coeficiente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_pos_w = [get_word(cv, w) for w in sorted_idx[range(-1, -11, -1)]]\n",
    "print(top_10_pos_w)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora obtengamos la importancia de las características (usando el _array_ `feature_importance`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_pos_importance = feature_importance[sorted_idx[range(-1, -11, -1)]]\n",
    "print(top_10_pos_importance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función `plot_importance` recibe una lista de palabras importantes y su importancia, y muestra en un gráfico de barras dichas palabras.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_importance(top10_w, top_10_impo):\n",
    "    'Función auxiliar que, dado las palabras más importantes y su importancia las grafica'\n",
    "    fig = plt.figure(figsize=(10, 6))\n",
    "    ax = sns.barplot(x=top10_w, y=top_10_impo)\n",
    "    _, x_labels = plt.xticks()\n",
    "    plt.setp(x_labels, rotation=40)\n",
    "    plt.ylabel('Feature Importance', fontsize=12)\n",
    "    plt.xlabel('Word', fontsize=12)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grafiquemos las palabras positivas más importantes:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_importance(top_10_pos_w, top_10_pos_importance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora obtengamos las 10 palabras negativas más importantes:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_neg_w = [get_word(cv, w) for w in sorted_idx[:10]]\n",
    "print(top_10_neg_w)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y su importancia:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_neg_importance = feature_importance[sorted_idx[:10]]\n",
    "print(top_10_neg_importance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego, como hicimos anteriormente, mostremos en una gráfica de barras su importancia.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_importance(top_10_neg_w, top_10_neg_importance)\n",
    "print(\"Most Important Words Used for Negative Sentiment\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 7: Ideas Para Mejorar: Añadir bigramas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una idea para mejorar el modelo anterior es añadir bigramas a la clasificación. El vector resultante tiene muchas características, una estrategia válida es disminuir la cantidad de palabras que tiene en cuenta, usando `max_df` para eliminar las palabras más frecuentes, o `min_df` para las menos frecuentes. Para analizar los bigramas, el inicializador de `CountVectorizer` tiene un parámetro `ngram_range`, que recibe una tupla, en la cual se especifca el límite inferior y superior del rango de valores `n` para las diferentes n-gramas de palabras que se extraerán."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(min_df=2, ngram_range=(1, 2))\n",
    "X = cv.fit_transform(texts_p + texts_n)\n",
    "X = X.toarray()\n",
    "X.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividimos de nuevo la nueva matriz de características y el vector de clases en conjuntos de entrenamiento y de prueba.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, train_size=0.70, random_state=23)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y volvemos a usar el clasificador `LogisticRegression`, para obtener la precisión con esta nueva matriz de características.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = LogisticRegression(solver='liblinear', max_iter=1000)\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_model.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora probemos el ejemplo '_The movie was not fun to watch_' visto anteriormente y observemos ahora como (debería) dar más probabilidades de pertenecer a la clase negativa añadiendo bigramas que cuando se usaban solo unigramas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_review = cv.transform([\"The movie was not fun to watch\"])\n",
    "lr_model.predict_proba(test_review)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 8: Ideas para Mejorar: Disminuir el umbral de corte de probabilidad\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra alternativa para la mejora es disminuyendo o aumentando el umbral de corte de probabilidad que usa `LogisticRegression` para clasificar los ejemplos en positivos o negativos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usemos la siguiente lista para establecer el umbral de posibles probabilidades:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_list = [0.4, 0.45, 0.5, 0.55, 0.6]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ello, predecimos las probabilidades de pertenencia a cada clase que se obtendría en el conjunto de prueba `X_test`, usando el método `predict_proba` del modelo de `LogisticRegression`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_proba_df = pd.DataFrame(lr_model.predict_proba(X_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego, dado el array de probabilidades, nos quedamos con aquellos valores que tengan una probabilidad mayor que el umbral como ejemplos positivos, y negativos en otro caso. Despues, calculamos la precisión obtenida con estos resultados en dependencia de `y_test`, la respuesta real usando la función `accuracy_score`, que recibe el array de clases real y el array de clases predecida.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in threshold_list:\n",
    "    print('\\n******** For i = {} ******'.format(i))\n",
    "    Y_test_pred = pred_proba_df.applymap(lambda x: 1 if x > i else 0)\n",
    "    test_accuracy = round(accuracy_score(\n",
    "        y_test, Y_test_pred.loc[:, 1].values), 3)\n",
    "    print('Accuracy: {}'.format(test_accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "11ffc019a02cc0e21e59860b66c88ea81995ce9237607e8ab2c087a287ee4867"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

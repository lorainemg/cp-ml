{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CP 4 Aprendizaje de Máquinas\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión Logística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta clase práctica, seguiremos usando el dataset de _Rotten Tomatoes_ para clasificar críticas positivas y negativas. Como en las clases anteriores, extraemos el contenido de los archivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "path_p = Path(\"txt_sentoken/pos\")\n",
    "path_n = Path(\"txt_sentoken/neg\")\n",
    "\n",
    "ds_p = list(path_p.iterdir())     # directorio donde están las críticas positivas\n",
    "ds_n = list(path_n.iterdir())     # directorio donde están las críticas negativas\n",
    "\n",
    "def convert_file_to_text(file_path: Path) -> str:\n",
    "    with open(file_path) as f:\n",
    "        return ''.join(f.readlines())\n",
    "    \n",
    "texts_p = [convert_file_to_text(file) for file in ds_p]    # Lista de críticas positivas\n",
    "texts_n = [convert_file_to_text(file) for file in ds_n]    # Lista de críticas negativas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 1: Regresión Logística aplicado al dataset de _Rotten Tomatoes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apliquemos el algoritmo visto en conferencia, Regresión Logística, para la clasificación de las críticas de _Rotten Tomatoes_. Comenzamos usando, como siempre, `CountVectorizer` para obtener una representación de bolsas de palabras en el dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "\n",
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(texts_p + texts_n)\n",
    "X = X.toarray()\n",
    "\n",
    "y = [1]*1000 + [0]*1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobamos el tamaño del vector de características:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividimos la matriz de características y el vector de clase en conjuntos de entrenamiento y de prueba, usando el 70% del dataset para entrenamiento. Esta vez, se usa el parámetro `random_state` para obtener la misma división en llamadas sucesivas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.70, random_state=23)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usemos ahora el clasificador `LogisticRegression` para realizar el entrenamiento y predicción del dataset en cuestión. El parámetro `solver` de `LogisticRegression` especifica el algoritmo de optimización a usar durante el entrenamiento. En caso que sea requerido, usar uno más sencillo como `liblinear` en vez del que tiene por defecto `sklearn` puede simplificar el proceso de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 2: Visualizando la Matriz de Confusión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el siguiente ejercicio, visualicemos la matriz de confusión, que especifica de los ejemplos negativos y positivos, cuáles fueron correctamente clasificados como negativos y positivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = plot_confusion_matrix(lr_model, X_test, y_test,\n",
    "                             display_labels=['Negative Class', 'Positive Class'],\n",
    "                             cmap=plt.cm.Blues,\n",
    "                             normalize='true')\n",
    "disp.ax_.set_title('Logistic Regression Confusion matrix, with normalization');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 3: Probando la clasificación de un texto en específico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, mostramos cómo se podría realizar la clasificación de un ejemplo específico, para ellos, comprobemos el orden en que las clases son mostradas mediante la propiedad `classes_` de la instancia de `LogisticRegression`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para probar el clasificador en un ejemplo específico, se debe primero vectorizar la oración de entrada, llamando el método `transform` _vectorizer_, que recibe una lista de _strings_. Luego, el método `predict` recibe la matriz de características y retorna un `array` con las clases clasificadas. El método `predict_proba` da más información, mostrando las probabilidades de pertenencia de cada clase, de acuerdo al orden mostrado de las clases en el método anterior.\n",
    "\n",
    "Probemos un ejemplo interesante, '*The movie was not fun to watch*', que a pesar de presentar una palabra que podría considerarse positiva ('*fun*', esta se encuentra negada y es en realidad una crítica negativa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 4: Vizualizando las Características más Importantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, visualicemos las características más importantes, es decir, las palabras más importantes para clasificar una crítica como negativa o positiva."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ello, tenemos que usar la propiedad de `Logistic Regression` de sklearn, `coef_`, que cuando el problema es binario nos brinda un `ndarray` de dimensión `(1,n_features)` que contiene los coeficiente de las características que resultan del entrenamiento.\n",
    "\n",
    "Luego, se crea `sorted_idx`, que contiene el índice de las características (palabras) que ordenarían el array según su importancia (de menor a mayor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = lr_model.coef_[0]\n",
    "sorted_idx = np.argsort(feature_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método auxiliar, `get_word`, dado el índice resultante de `sorted_idx`, retorna la palabra que le corresponde a dicho índice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word(cv: CountVectorizer, w_idx: int) -> str:\n",
    "    \"Given the index of a word, finds in the vocabulary of the CountVectorizer the word\"\n",
    "    return list(cv.vocabulary_.keys())[list(cv.vocabulary_.values()).index(w_idx)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtengamos entonces el orden de las 10 palabras más importantes para clasificar una crítica como positiva. Notar que las características positivas son aquellas que tienen un mayor coeficiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora obtengamos la importancia de las características (usando el _array_ `feature_importance`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función `plot_importance` recibe una lista de palabras importantes y su importancia, y muestra en un gráfico de barras dichas palabras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_importance(top10_w, top_10_impo):\n",
    "    'Función auxiliar que, dado las grafica las palabras más importantes y su importancia'\n",
    "    fig = plt.figure(figsize=(10, 6))\n",
    "    ax = sns.barplot(x=top10_w, y=top_10_impo)\n",
    "    _, x_labels = plt.xticks()\n",
    "    plt.setp(x_labels, rotation=40)\n",
    "    plt.ylabel('Feature Importance', fontsize=12)\n",
    "    plt.xlabel('Word', fontsize = 12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grafiquemos las palabras positivas más importantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora obtengamos las 10 palabras negativas más importantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y su importancia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego, como hicimos anteriormente, mostremos en una gráfica de barras su importancia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 7: Ideas Para Mejorar: Añadir bigramas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una idea para mejorar el modelo anterior es añadir bigramas a la clasificación. El vector resultante tiene muchas características, una estrategia válida es disminuir la cantidad de palabras que tiene en cuenta, usando `max_df` para eliminar las palabras más frecuentes, o `min_df` para las menos frecuentes. Para analizar los bigramas, el inicializador de `CountVectorizer` tiene un parámetro `ngram_range`, que recibe una tupla, en la cual se especifca el límite inferior y superior del rango de valores `n` para las diferentes n-gramas de palabras que se extraerán."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobamos el tamaño del vector de características:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividimos de nuevo la nueva matriz de características y el vector de clases en conjuntos de entrenamiento y de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.70, random_state=23)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y volvemos a usar el clasificador `LogisticRegression`, para obtener la precisión con esta nueva matriz de características."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora probemos el ejemplo '*The movie was not fun to watch*' visto anteriormente y observemos ahora como (debería) dar más probabilidades de pertenecer a la clase negativa añadiendo bigramas que cuando se usaban solo unigramas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 8: Ideas para Mejorar: Disminuir el umbral de corte de probabilidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra alternativa para la mejora es disminuyendo o aumentando el umbral de corte de probabilidad que usa `LogisticRegression` para clasificar los ejemplos en positivos o negativos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usemos la siguiente lista para establecer el umbral de posibles probabilidades:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_list = [0.4, 0.45, 0.5, 0.55, 0.6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ello, predecimos las probabilidades de pertenencia a cada clase que se obtendría en el conjunto de prueba `X_test`, usando el método `predict_proba` del modelo de `LogisticRegression`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego, dado el array de probabilidades, nos quedamos con aquellos valores que tengan una probabilidad mayor que el umbral como ejemplos positivos, y negativos en otro caso. Despues, calculamos la precisión obtenida con estos resultados en dependencia de `y_test`, la respuesta real usando la función `accuracy_score`, que recibe el array de clases real y el array de clases predecida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "11ffc019a02cc0e21e59860b66c88ea81995ce9237607e8ab2c087a287ee4867"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
